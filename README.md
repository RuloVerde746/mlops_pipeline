# ü§ñ MLOps Pipeline - Predicci√≥n de Cr√©ditos

**Versi√≥n actual: 1.3.0**

Este repositorio contiene la implementaci√≥n paso a paso de un pipeline de MLOps automatizado para la predicci√≥n de riesgo crediticio (Credit Scoring).

## üìÇ Estructura del Proyecto

*   `src/cargar_datos.py`: Script para cargar y preparar el dataset [Base_de_datos.xlsx](cci:7://file:///c:/Users/RuVe7/Desktop/ProyectoM5_MatiasGutierrez/Pi_pt_ds_01/mlops_pipeline/Base_de_datos.xlsx:0:0-0:0).
*   `src/comprension_eda.ipynb`: An√°lisis Exploratorio de Datos (EDA) para entender las distribuciones, identificar outliers (ej. `tipo_credito` muy poco frecuentes) y plantear relaciones con la variable objetivo `Pago_atiempo`.
*   [requirements.txt](cci:7://file:///c:/Users/RuVe7/Desktop/ProyectoM5_MatiasGutierrez/Pi_pt_ds_01/mlops_pipeline/requirements.txt:0:0-0:0): Dependencias de Python necesarias para correr el pipeline.

## üõ† Instalaci√≥n y Uso Local

1.  **Clonar este repositorio:**
    ```bash
    git clone https://github.com/RuloVerde746/mlops_pipeline/tree/developer
    cd Pi_pt_ds_01/mlops_pipeline
    ```
2.  **Crear y activar el entorno virtual:**
    ```bash
    python -m venv venv
    # En Windows:
    .\venv\Scripts\activate
    ```
3.  **Instalar dependencias necesarias:**
    ```bash
    pip install -r requirements.txt
    ```

## üìä Avances (Versi√≥n actual 1.0.1)
- [x] Configuraci√≥n del entorno de desarrollo (venv, requirements).
- [x] Construcci√≥n de la funci√≥n base de carga de datos sin conexi√≥n forzada.
- [x] EDA visual completado (Tratamiento de nulos cruzando variables, filtrado de categor√≠as con poco volumen, an√°lisis cruzado de morosidad).

## üìä Avances (Versi√≥n actual 1.1.0)
- [x] Configuraci√≥n del entorno de desarrollo (venv, requirements).
- [x] Construcci√≥n de la funci√≥n base de carga de datos sin conexi√≥n forzada.
- [x] EDA visual completado (Tratamiento de nulos cruzando variables, filtrado de categor√≠as con poco volumen, an√°lisis cruzado de morosidad).
- [x] **Feature Engineering robusto** (`ft_engineering.py`) - Pipeline completo con sklearn ColumnTransformer
- [x] **Model Training & Evaluation** (`model_training_evaluation.py`) - Entrenamiento y evaluaci√≥n de 5 modelos con selecci√≥n autom√°tica

## ü§ñ Feature Engineering (`src/ft_engineering.py`)

### üéØ Prop√≥sito
Implementa un pipeline robusto de feature engineering para la predicci√≥n de pago a tiempo de cr√©ditos.

### üîß Funcionalidades Principales
- **Feature Creation**: Ratios financieros, indicadores de riesgo, caracter√≠sticas de sector
- **Data Preprocessing**: Imputaci√≥n autom√°tica, encoding categ√≥rico, escalado num√©rico
- **Pipeline Robusto**: ColumnTransformer + SimpleImputer para manejo de NaNs
- **Train-Test Split**: Divisi√≥n estratificada con random_state=42

### üìà Caracter√≠sticas Generadas
- **Ratios**: deuda/ingresos, cuota/ingresos, saldo/capital
- **Indicadores**: tiene_mora, m√∫ltiples_pr√©stamos, alta_consulta
- **Sectoriales**: total_cr√©ditos_formales, prop_cr√©ditos_formales
- **Diferenciales**: diff_puntajes (puntaje - puntaje_datacredito)

### ‚úÖ Resultados
- **Dataset procesado**: 10,760 muestras ‚Üí 36 caracter√≠sticas finales
- **Distribuci√≥n**: 95.5% clase 1 (paga), 4.5% clase 0 (no paga)
- **Sin NaNs**: Pipeline robusto garantiza datos limpios

## üèÜ Model Training & Evaluation (`src/model_training_evaluation.py`)

### üéØ Prop√≥sito
Entrena, eval√∫a y selecciona autom√°ticamente el mejor modelo de clasificaci√≥n para predicci√≥n de pago a tiempo.

### ü§ñ Modelos Evaluados
| Modelo | Tipo | Caracter√≠sticas |
|--------|------|----------------|
| **Logistic Regression** | Lineal | R√°pido, interpretable |
| **SVC** | Kernel RBF | Bueno para datos complejos |
| **Decision Tree** | √Årbol | Muy interpretable |
| **Random Forest** | Ensemble | Reduce overfitting |
| **XGBoost** | Gradient Boosting | Alto rendimiento |

### üìä M√©tricas de Evaluaci√≥n
- **Accuracy**: Proporci√≥n de predicciones correctas
- **Precision**: Minimiza falsos positivos
- **Recall**: Minimiza falsos negativos  
- **F1-Score**: Balance precision-recall (criterio de selecci√≥n)

### üèÖ Resultados Obtenidos
| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|---------|----------|
| **Decision Tree**  | **1.0000** | **1.0000** | **1.0000** | **1.0000** |
| Random Forest | 1.0000 | 1.0000 | 1.0000 | 1.0000 |
| XGBoost | 1.0000 | 1.0000 | 1.0000 | 1.0000 |
| Logistic Regression | 0.9991 | 1.0000 | 0.9990 | 0.9995 |
| SVC | 0.9986 | 0.9995 | 0.9990 | 0.9993 |

### üíæ Artefactos Generados
- **Modelo**: `mejor_modelo_decision_tree.pkl` - Modelo ganador
- **Preprocesador**: `preprocesador.pkl` - Pipeline de transformaci√≥n
- **Referencia**: `data_referencia.csv` - Datos base para monitoreo PSI
- **Metadatos**: `model_metadata.pkl` - Informaci√≥n completa del modelo

### üöÄ C√≥mo Usar
```bash
# Entrenar y evaluar todos los modelos
python src/model_training_evaluation.py
```

El c√≥digo seleccionar√° autom√°ticamente el mejor modelo (Decision Tree) y guardar√° todos los artefactos necesarios para producci√≥n.

---

## üìä Avances (Versi√≥n actual 1.2.0)

### üîç AVANCE 3: Model Monitoring y Data Drift Detection
- [x] **Sistema de monitoreo completo** (`src/model_monitoring.py`)
- [x] **Detecci√≥n de data drift** con m√∫ltiples m√©tricas estad√≠sticas:
  - **PSI** (Population Stability Index) - Detecta cambios en distribuci√≥n poblacional
  - **KS** (Kolmogorov-Smirnov) - Compara distribuciones acumuladas  
  - **Jensen-Shannon** - Mide divergencia entre distribuciones
  - **Chi-cuadrado** - Para variables categ√≥ricas
- [x] **Sistema de alertas autom√°tico** con 3 niveles:
  - üî¥ **CRITICAL**: 2+ m√©tricas cr√≠ticas o 1 cr√≠tica + 2 advertencias
  - üü° **WARNING**: 1 cr√≠tica o 2+ advertencias
  - üü¢ **NORMAL**: M√©tricas dentro de umbrales normales
- [x] **Reportes HTML interactivos** con visualizaciones y tablas de m√©tricas
- [x] **Gr√°ficos comparativos** para variables con alertas (histogramas, box plots, Q-Q plots)
- [x] **Datos para dashboard Streamlit** (`assets/streamlit_dashboard_data.pkl`)
- [x] **Estructura de archivos organizada**:
  - `assets/` - Reportes y datos generados
  - `assets/images/` - Gr√°ficos de monitoreo
  - `assets/drift_report.html` - Reporte principal
  - `assets/drift_report.json` - Datos en formato JSON

### üèÜ Resultados del Monitoreo
| M√©trica | Resultado |
|----------|-----------|
| **Variables analizadas** | 37 |
| **Alertas cr√≠ticas** | 4 (variables: 1, 4, 24, prediction) |
| **Alertas de advertencia** | 17 variables |
| **Variables normales** | 16 variables |

### üöÄ C√≥mo Usar el Monitoreo
```bash
# Ejecutar monitoreo completo
python src/model_monitoring.py
```

### üìÅ Archivos Generados por el Monitoreo
- **`assets/drift_report.html`** - Reporte HTML completo
- **`assets/drift_report.json`** - Datos en formato JSON
- **`assets/images/drift_plot_*.png`** - Gr√°ficos de variables con alertas
- **`assets/streamlit_dashboard_data.pkl`** - Datos para dashboard Streamlit

---

## üöÄ Avance 4: Model Deployment (API)

### üéØ Objetivos Logrados
- [x] **Disponibilizaci√≥n del modelo mediante una API**: Implementaci√≥n de un servicio REST para predicciones en tiempo real y por lotes.
- [x] **Creaci√≥n de imagen Docker**: Preparaci√≥n del entorno contenedorizado con todas las librer√≠as y el c√≥digo necesario para la aplicaci√≥n.

### üõ† Despliegue del Modelo (`src/model_deploy.py`)

Este script representa el n√∫cleo del despliegue productivo, utilizando **FastAPI** para exponer el modelo como un servicio robusto y escalable.

#### üîß Funcionalidades y Responsabilidades
- **Carga de Modelos**: Carga autom√°tica del mejor modelo (`mejor_modelo_decision_tree.pkl`) y su preprocesador (`preprocesador.pkl`).
- **L√≥gica de Predicci√≥n**: Implementa la transformaci√≥n de datos de entrada asegurando consistencia con el entrenamiento.
- **Endpoints REST**:
    - `POST /predict`: Permite enviar m√∫ltiples registros para predicci√≥n por lotes (batch).
    - `POST /predict_single`: Optimizado para predicciones individuales r√°pidas.
    - `GET /model_info`: Proporciona metadatos sobre la versi√≥n y tipo de modelo cargado.
    - `GET /health`: Verifica el estado de salud del servicio y la carga de artefactos.
- **Soporte Pydantic**: Validaci√≥n estricta de datos de entrada mediante esquemas definidos.

#### üöÄ C√≥mo Ejecutar la API
```bash
# Iniciar el servidor Uvicorn
python src/model_deploy.py
```
La documentaci√≥n interactiva estar√° disponible autom√°ticamente en `http://localhost:8000/docs`.

---

## üìà Avance 5: Visualizaci√≥n y Dashboard Interactivo

### üéØ Objetivos Logrados
- [x] **Dashboard de Monitoreo con Streamlit**: Interfaz gr√°fica para visualizar la salud del modelo en tiempo real.
- [x] **Integraci√≥n de Logs Persistentes**: Sistema de auditor√≠a que permite ver el estado del pipeline desde la terminal de Docker o PowerShell.
- [x] **An√°lisis de Drift Visual**: Pesta√±as dedicadas para alertas cr√≠ticas, incluyendo histogramas y gr√°ficos de estabilidad.

---

## üèÅ Gu√≠a Paso a Paso: Ejecuci√≥n Completa del Proyecto

Sigue este flujo para ejecutar el sistema desde cero hasta la visualizaci√≥n en el dashboard.

### 1. Preparaci√≥n del Entorno
Antes de empezar, aseg√∫rate de tener instalado **Docker Desktop** y Python 3.9+.
- Crea tu entorno virtual: `python -m venv venv`
- Act√≠valo: `.\venv\Scripts\activate` (Windows)
- Instala dependencias: `pip install -r requirements.txt`

### 2. Procesamiento de Datos y Entrenamiento
Ejecuta los scripts en este orden para generar los artefactos del modelo:
1. **Carga de Datos**: `python src/cargar_datos.py` (Procesa el Excel inicial).
2. **Entrenamiento**: `python src/model_training_evaluation.py` (Entrena 5 modelos, selecciona el mejor y guarda `mejor_modelo_decision_tree.pkl`).

### 3. Despliegue con Docker Desktop
**Docker Desktop** es fundamental aqu√≠ porque permite "empaquetar" nuestra API (`FastAPI`) junto con todas sus dependencias en un contenedor. Esto garantiza que el modelo funcione exactamente igual en tu m√°quina que en un servidor de producci√≥n.
- Ejecuta: `docker-compose up --build`
- Esto levantar√° la API en el puerto `8000`. Puedes verificarlo en `http://localhost:8000/docs`.

### 4. Generaci√≥n de Monitoreo (Data Drift)
Para simular el paso del tiempo y verificar si el modelo sigue siendo preciso, ejecutamos el sistema de monitoreo:
- Ejecuta: `python src/model_monitoring.py`
- Este script comparar√° los datos originales contra los nuevos, generar√° alertas y crear√° los archivos en la carpeta `assets/`.

### 5. Visualizaci√≥n en Streamlit
**Streamlit** es la herramienta que convierte nuestros scripts de datos en una aplicaci√≥n web interactiva. No necesitas saber HTML/CSS; Streamlit interpreta el c√≥digo Python para crear el dashboard.
- Ejecuta: `streamlit run src/streamlit_app.py`
- Se abrir√° una ventana en tu navegador (`http://localhost:8501`) donde ver√°s:
    - La salud general del modelo.
    - Las variables que han sufrido desviaciones (Drift).
    - Recomendaciones autom√°ticas sobre si debes reentrenar el modelo.

---
> **Tip de Depuraci√≥n**: Si activas el **"Modo Depuraci√≥n"** en el sidebar de Streamlit, podr√°s ver logs t√©cnicos adicionales y la estructura cruda de los datos procesados.

